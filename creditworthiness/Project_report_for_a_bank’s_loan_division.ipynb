{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing borrowers’ risk of defaulting\n",
    "\n",
    "Your project is to prepare a report for a bank’s loan division. You’ll need to find out if a customer’s marital status and number of children has an impact on whether they will default on a loan. The bank already has some data on customers’ credit worthiness.\n",
    "\n",
    "Your report will be considered when building a **credit scoring** of a potential customer. A ** credit scoring ** is used to evaluate the ability of a potential borrower to repay their loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1. Open the data file and have a look at the general information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name '_path'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-3bbfd6e341bb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSnowballStemmer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstem\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mWordNetLemmatizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mcycler\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcycler\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolorbar\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mrcsetup\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstyle\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\matplotlib\\colorbar.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0martist\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mmartist\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcollections\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mcollections\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcbook\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocstring\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 11\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mPath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     12\u001b[0m from .transforms import (Bbox, IdentityTransform, Transform, TransformedBbox,\n\u001b[0;32m     13\u001b[0m                          TransformedPatchPath, TransformedPath)\n",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python36\\site-packages\\matplotlib\\path.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 17\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrcParams\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     18\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mcbook\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0m_to_unmasked_float_array\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msimple_linear_interpolation\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name '_path'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 21525 entries, 0 to 21524\n",
      "Data columns (total 12 columns):\n",
      "children            21525 non-null int64\n",
      "days_employed       19351 non-null float64\n",
      "dob_years           21525 non-null int64\n",
      "education           21525 non-null object\n",
      "education_id        21525 non-null int64\n",
      "family_status       21525 non-null object\n",
      "family_status_id    21525 non-null int64\n",
      "gender              21525 non-null object\n",
      "income_type         21525 non-null object\n",
      "debt                21525 non-null int64\n",
      "total_income        19351 non-null float64\n",
      "purpose             21525 non-null object\n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 2.0+ MB\n",
      "None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('credit_scoring_eng.csv')\n",
    "\n",
    "#general information of the data\n",
    "print(data.info())\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visual checking last or first values of the data\n",
    "data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the interest of analyzing data for errors I decide to separate variable into two groups: categorical and numerical\n",
    "categorical data - Descriptive data containing a small number of values inside - from 2 to 20 approximately values.\n",
    "numerical - Quantitative characteristics of the client, for the analysis of which average measures are used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets check numerical variables\n",
    "print(\"Numerical variables:\")\n",
    "print()\n",
    "\n",
    "#let's look of NAns present in var's where observations are less than in other variables\n",
    "print('NA`s in variables:')\n",
    "print(data[['total_income', 'days_employed']].isna().count())\n",
    "print()\n",
    "\n",
    "#obviouse problem was mentioned in variable 'days_employed'\n",
    "#find the percent of the garbage data in problem variable 'days_emplyed'\n",
    "print(\"- Percent of the garbage data in problem variable 'days_emplyed': {:.2%}\".format(\n",
    "    data['days_employed'][data['days_employed'] < 0].count() / data['days_employed'].count()))\n",
    "\n",
    "#conseder other numeric vars \"dob_years\"\n",
    "#let's see how many customers of different ages\n",
    "#print(data['dob_years'].value_counts().sort_values(ascending=False))\n",
    "#investigation shown that we have zero-age clients. This is an error. Lets count how much of them. \n",
    "print('- There are {} zero-age clients, and {} less-than-zero-age in \"dob_years\" variable'.format(\n",
    "    data['dob_years'][data['dob_years'] == 0].count(), \n",
    "    data['dob_years'][data['dob_years'] < 0].count()))\n",
    "\n",
    "#conseder other numeric vars \"total_income\"\n",
    "print('- There are {} observations in total (it`s less than observations in the entire data becouse of NA`s), {} - zero-income clients, and {} less-than-zero-income in \"total_income\" variable (looks fine)'.format(\n",
    "    data['total_income'].count(),\n",
    "    data['total_income'][data['total_income'] == 0].count(),\n",
    "    data['total_income'][data['total_income'] < 0].count()))\n",
    "print()\n",
    "#data in 'total_income' var looks fine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#consider categorical variables separately\n",
    "print(\"Categorical variables:\")\n",
    "print()\n",
    "\n",
    "#print(data['children'].value_counts())\n",
    "print('- There are {} observations in total, {} - 20 childrens, and {} -1 in \"children\" variable'.format(\n",
    "    data['children'].count(),\n",
    "    data['children'][data['children'] == 20].count(),\n",
    "    data['children'][data['children'] < 0].count()))\n",
    "print()\n",
    "\n",
    "#print(data['education'].value_counts())\n",
    "#print()\n",
    "#seen case-sensitively duplicates \n",
    "\n",
    "#print(data['family_status'].value_counts())\n",
    "#print()\n",
    "#everything fine with this data \n",
    "\n",
    "#print(data['gender'].value_counts())\n",
    "#print()\n",
    "#seen statistically insignificant category \"XNA\" with one observation\n",
    "\n",
    "#print(data['income_type'].value_counts())\n",
    "#print()\n",
    "#seen statistically insignificant 3 category \"unemployed\", \"student\" and \"paternity / maternity leave\" with less than two observation\n",
    "#observation \"entrepreneur\" could be include to the \"business\" category\n",
    "\n",
    "#print(data['debt'].value_counts())\n",
    "#print()\n",
    "#everything fine with this data \n",
    "\n",
    "#print(data['purpose'].value_counts())\n",
    "#print()\n",
    "#Seen a lot of different purposes. Looks like it needs unification in large groups."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seen that we have data about 21525 people. Data containces int, float and object tipes of the 12 variables. Column 'total_income' as 'days_employed' doesn't equal to the number of observation of the other variables in the data - 19351 vs 21525. Also data errors detected by visual evaluation in column 'days_employed'. Maybe data contains more errors like this. It would be seen after investigation in the next steps.\n",
    "\n",
    "After a deeper study of the variables individually, a number of errors were identified. \n",
    "\n",
    "**Missing values**\n",
    "Were identify 101 zero-age clients, and 0 less-than-zero-age in \"dob_years\" variable. \"total_income\" and \"days_emplyed\" variables has less observations that in the data 19351 vs 21525 becouse of NA's. \n",
    "\n",
    "**Data type replacement**\n",
    "The days_employed variable in type 'float' must be replaced with type '.int' because day is an integer. \n",
    "\n",
    "**Processing duplicates**\n",
    "In 'education' variable seen case-sensitively duplicates. Also in \"children\" variable discovered 76 observetion with 20 children and 47 with -1 children. It's abnormal values. It doesn't impossible that some of the clients has 20 children, but if that were true we would see some kind of normal distribution. But it isn't observed. Instead we see huge leap from 5 to 20 children. Highly possible that in clients have 2 children instead 20, and 1 instead -1. Additional symbols is the reason of the human factor. The variable 'days_emplyed' consist 82.2% nagative values. Negative values needs deeper investigation.\n",
    "\n",
    "**Categorizing Data**\n",
    "Investigation of 'gender' variable shown statistically insignificant category \"XNA\" with one observation. Also in 'income_type' var seen tree statistically insignificant categories \"unemployed\", \"student\" and \"paternity / maternity leave\" with less than two observations. Observation \"entrepreneur\" could be include to the \"business\" category. Insignificant categories could be reduce. In the last variable 'purpose' was seen a lot of different options of purposes. It seems that they need to be unify in larger groups. A lot of nagative values, in the variable 'days_emplyed', it mean that this variable couldn't be used for analises in this form. Maybe it make sense to divide them into two groups. And finally variables such as 'days_emplyed' and 'total_income' could by unified to more general groups too."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Data preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#delete NA\n",
    "data = data.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for the mistakes in the data, in general, I found of that two variable has less observations than others. I made an assumption that one’s has NA's. In the credit banking segment income and work experience factors has a critical meaning, so the present of NA's could relate to some personal reasons of the clients. Maybe they said unreliable info and then this info were delete from the base. I decided to replace NA with zero, because it provides an opportunity for the further stay analisis and making a segmentation. Filtering zeros is not a problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data type replacement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'days_employed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert to int\n",
    "data['days_employed'] = data['days_employed'].astype('int')\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The days_employed variable in type 'float' must be replaced with type '.int' because day is an integer.\n",
    "I used `.astype('int')` because it works for this data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Processing duplicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'children'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#delete '-' and '0' from 'children' variable\n",
    "data.loc[data['children'] == 20, 'children'] = 2\n",
    "data.loc[data['children'] == -1, 'children'] = 1\n",
    "print(data['children'].value_counts().sort_values())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'days_employed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's investigate 'days_employed' variable deeply. Particularly the nature of negative values.\n",
    "# Build histogram to see wich destribution observatioins has\n",
    "plt.hist(data['days_employed'], bins=50)\n",
    "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#It's seen that variable consist two groups of observations\n",
    "#One group consist of 100% nembers less than zero. Values in range from 24.14 to 18388.95 days employed\n",
    "#It highly possible that minuses it's only technical error, and we can easily cut them.\n",
    "plt.hist(data['days_employed'][data['days_employed'] < 0], bins=50)\n",
    "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');\n",
    "\n",
    "print()\n",
    "print('range: min - {:.2f}, max - {:.2f}'.format(\n",
    "    data['days_employed'][data['days_employed'] < 0].abs().min(),\n",
    "    data['days_employed'][data['days_employed'] < 0].abs().max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The second group consist values in range from from 328 728.72, to 401 755.40 days employed\n",
    "plt.hist(data['days_employed'][data['days_employed'] > 0], bins=50)\n",
    "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');\n",
    "print(stats.shapiro(data['days_employed'][data['days_employed'] > 0].abs()))\n",
    "print()\n",
    "print('range: min - {:.2f}, max - {:.2f}'.format(\n",
    "    data['days_employed'][data['days_employed'] > 0].min(),\n",
    "    data['days_employed'][data['days_employed'] > 0].max()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discovering the percent of observations in groups\n",
    "print(\"Percent of observations in groups in variable 'days_emplyed': {:.2%} - <0; {:.2%} - 0; {:.2%} - >0\".format(\n",
    "    data['days_employed'][data['days_employed'] < 0].count() / data['days_employed'].count(),\n",
    "    data['days_employed'][data['days_employed'] == 0].count() / data['days_employed'].count(),\n",
    "    data['days_employed'][data['days_employed'] > 0].count() / data['days_employed'].count()))\n",
    "print()\n",
    "\n",
    "#let's delete minus symbol as a result of a technical issue\n",
    "data['days_employed'] = data['days_employed'].abs()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'education'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reducing case to the low level for the all types of education\n",
    "data['education'] = data['education'].str.lower()\n",
    "data['education'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To testing data for an errors or duplicates I used \".value_counts()\" method. It's good function for variables which consist not too much values. I find that 'children', 'education' and 'days_employed' data consists some mistakes. It's highly possible, that in 'children' and 'education' vars has a human factor error - cases-sensitively errors and extra symbols. \n",
    "For investigation of the negative values for 'days_employed' variable I decided to check if data in the var consistent or not. For this I built histogram, and surprisely discovered two set of data. And, expectedly, one of the sets was with negative values. It's point to the some systematically emerged error. So I decided to delete extra symbol \"-\" for all set by applying function \"abs()\". "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorizing Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'days_employed'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide the data in var 'days_employed' into three groups 'youths' 'veterans' and 'NA'\n",
    "#values for separetion:\n",
    "#print(data['days_employed'][data['days_employed'] < 0].abs().max())\n",
    "#print(data['days_employed'][data['days_employed'] > 0].abs().min())\n",
    "\n",
    "def employed_fun(day):\n",
    "    if 0 < day < 18390:\n",
    "        return 'youths'\n",
    "    if day > 328727:\n",
    "        return 'veterans'\n",
    "    if day == 0:\n",
    "        return 'NA'\n",
    "    return 'Not a number'\n",
    "    \n",
    "data['employed_satus'] = data['days_employed'].apply(employed_fun)\n",
    "print(data['employed_satus'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'total_income'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets chek var 'total_income' of clients\n",
    "plt.hist(data['total_income'], bins=50)\n",
    "plt.gca().set(title='Frequency Histogram', ylabel='Frequency');\n",
    "#as seen destribution doesn't shown any visible groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lets look how much observations in in approximate groups. I used an average salary 50k in SPb, Russia\n",
    "print(data[data['total_income'] < 50000]['total_income'].value_counts(bins=3))\n",
    "print(data[data['total_income'] > 50000]['total_income'].value_counts(bins=3))\n",
    "\n",
    "#building a function for creating a new grouping variable 'income_group'\n",
    "def income_fun(amount):\n",
    "    if amount <= 20000:\n",
    "        return \"poor\"\n",
    "    if 20000 < amount <= 40000:\n",
    "        return \"lower_middle\"\n",
    "    if 40000 < amount <= 65000:\n",
    "        return \"middle\"\n",
    "    if 65000 < amount:\n",
    "        return \"higher_middle\"\n",
    "    return \"NA\"\n",
    "\n",
    "#applying funtion to the data            \n",
    "data['income_group'] = data['total_income'].apply(income_fun)\n",
    "print(data['income_group'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'income_type'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's combine the meaning of “entrepreneur” on “business”\n",
    "data.loc[data['income_type'] == 'entrepreneur', 'income_type'] = 'business'\n",
    "#Delete insignificant \"unemployed\", \"paternity / maternity leave\" and \"student\"\n",
    "data = data.drop(data[data.income_type == \"unemployed\"].index)\n",
    "data = data.drop(data[data.income_type == \"paternity / maternity leave\"].index)\n",
    "data = data.drop(data[data.income_type == \"student\"].index)\n",
    "\n",
    "print(data['income_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'gender'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(data[data.gender == \"XNA\"].index)\n",
    "data['gender'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 'purpose'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look to the variable 'purpse' closly and find counting by meaning values\n",
    "data['purpose'].value_counts()\n",
    "\n",
    "#As seen there are many. Let's getered output in a list for stemming\n",
    "purpose_dict = dict(data['purpose'].value_counts())\n",
    "purpose_names = []\n",
    "for name in purpose_dict:\n",
    "    purpose_names.append(name)\n",
    "\n",
    "print(purpose_names)\n",
    "print()\n",
    "print()\n",
    "\n",
    "# Creating a list of most common stems from the previously created list of proposes\n",
    "import nltk\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmed_word = []\n",
    "english_stemmer = SnowballStemmer('english')\n",
    "for purpose in purpose_names:\n",
    "    for word in purpose.split():\n",
    "        stemmed_word.append(english_stemmer.stem(word))\n",
    "        \n",
    "from collections import Counter\n",
    "print(Counter(stemmed_word).most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#building a function for creating a new grouping variable 'purpose_group' based on var 'purpose'\n",
    "def purpose_fun(purpose_names):\n",
    "    for word in purpose_names.split():\n",
    "        stemmed_word = english_stemmer.stem(word)\n",
    "        if stemmed_word == 'car':\n",
    "            return \"car\" \n",
    "        if stemmed_word == 'educ':\n",
    "            return \"education\"\n",
    "        if stemmed_word == 'univers':\n",
    "            return \"education\"\n",
    "        if stemmed_word == 'transact':\n",
    "            return \"commercial\"\n",
    "        if stemmed_word == 'rent':\n",
    "            return \"commercial\"\n",
    "        if stemmed_word == 'commerci':\n",
    "            return \"commercial\"\n",
    "        if stemmed_word == 'wed':\n",
    "            return \"wedding\"\n",
    "\n",
    "#applying funtion to the data            \n",
    "data['purpose_group'] = data['purpose'].apply(purpose_fun)\n",
    "data['purpose_group'] = data['purpose_group'].fillna(value='real estate')\n",
    "\n",
    "#Сheking for NA's\n",
    "print(data['purpose'][data['purpose_group'].isna()].value_counts())\n",
    "print()\n",
    "\n",
    "#looking how much observations per any variable\n",
    "print(data['purpose_group'].value_counts())\n",
    "print()\n",
    "\n",
    "#Checking the correct distribution of values into groups \n",
    "data_pivot = data.pivot_table(\n",
    "index=['purpose_group', 'purpose'],\n",
    "values='total_income', \n",
    "aggfunc='count')\n",
    "print(data_pivot)\n",
    "print()\n",
    "\n",
    "#data2.groupby('purpose_group')['purpose'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's look if everything fine\n",
    "data.info()\n",
    "data.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On the previous step I found two groups inside value **'days_employed'**. Then I decided to split it into three groups *'youths'* *'veterans'* and *'NA'*. Group 'NA' is equal to the zero. I used this name because zero means absent of the information.\n",
    "I discovered **'total_income'** by using histogram but as seen distribution doesn't show any visible groups. But further analysis required to divide this variable to the groups. I decided to create a groups, grounded on expert knowledge about minimum income, average and high salary. Last affected var was **'gender'**, I cut out only one value, because it couldn't give us significant information. In the last variable **'purpose'** was seen a lot of different options of purposes. It seems that they need to be unify in larger groups. First I found grouping values by using stem method. It's easiest then lennomination and good enough for this task. So I revealed: *wedding* - wed; *commercial* - transact, rent, commerci; *car* - car; *education* - educ, univers; *real estate* - for the rest. By creating new function, I made a new variable. It wasn't easy to redistribute values of **'purpose'** among grouping values. Because some words are found in several values at once. Pivot table helped me in solving this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3. Major questions of the research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Is there a relation between having kids and repaying a loan on time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_pivot = data.pivot_table(\n",
    "index=['children'],\n",
    "columns='debt',\n",
    "values='family_status_id', \n",
    "aggfunc='count')\n",
    "\n",
    "data_pivot['ratio'] = data_pivot[1]/data_pivot[0]*100\n",
    "print(data_pivot.sort_values(by='ratio', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Families without children and with three children repay debts better. But in a group with three children, there are too few observations and they may be insignificant. As a conclusion - families with children repay debts worse."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Is there a relation between marital status and repaying a loan on time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pivot = data.pivot_table(\n",
    "index=['family_status'],\n",
    "columns='debt',\n",
    "values='family_status_id', \n",
    "aggfunc='count')\n",
    "\n",
    "data_pivot['ratio'] = data_pivot[1]/data_pivot[0]*100\n",
    "print(data_pivot.sort_values(by='ratio', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unmarried and divorced repaying loans worse than married. The best payers are divorced and widowers / widows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Is there a relation between income level and repaying a loan on time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_pivot = data.pivot_table(\n",
    "index=['income_group'],\n",
    "columns='debt',\n",
    "values='family_status_id', \n",
    "aggfunc='count')\n",
    "\n",
    "data_pivot['ratio'] = data_pivot[1]/data_pivot[0]*100\n",
    "print(data_pivot.sort_values(by='ratio', ascending=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's try to rebuild our groups to know if we could get data with another proportion of repay a loan\n",
    "def income_fun(amount):\n",
    "    if amount <= 20000:\n",
    "        return \"poor\"\n",
    "    if 20000 < amount <= 40000:\n",
    "        return \"lower_middle\"\n",
    "    if 40000 < amount <= 125000:\n",
    "        return \"middle\"\n",
    "    if 125000 < amount:\n",
    "        return \"higher_middle\"\n",
    "    return \"NA\"\n",
    "\n",
    "#applying funtion to the data            \n",
    "data['income_group'] = data['total_income'].apply(income_fun)\n",
    "print(data['income_group'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#build another data pivot\n",
    "data_pivot = data.pivot_table(\n",
    "index=['income_group'],\n",
    "columns='debt',\n",
    "values='family_status_id', \n",
    "aggfunc='count')\n",
    "\n",
    "data_pivot['ratio'] = data_pivot[1]/data_pivot[0]*100\n",
    "print(data_pivot.sort_values(by='ratio', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observed interesting results. First data groping variant showed as expected, that the richer clients the better chance to repay a loan. But after shifting upper limit, ratio of probability changed for rich people. It shows that people with high income worse repay loan the poorest clients. Only one important think require high attention. The total amount of people in 'higher_middle' group is 44. It's not enough for comparison with another large groups. This conclusion has to be verified on larger data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - How do different loan purposes affect on-time repayment of the loan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pivot = data.pivot_table(\n",
    "index=['purpose_group'],\n",
    "columns='debt',\n",
    "values='total_income', \n",
    "aggfunc='count')\n",
    "\n",
    "data_pivot['ratio'] = data_pivot[1]/data_pivot[0]*100\n",
    "print(data_pivot.sort_values(by='ratio', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A loan for real estate, both for life and business, is better repaid than for a car or education. Interestingly, the wedding loans only a little worse repaid than real estate loans."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Is there education level affect on-time repayment of the loan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pivot = data.pivot_table(\n",
    "index=['education'],\n",
    "columns='debt',\n",
    "values='total_income', \n",
    "aggfunc='count')\n",
    "\n",
    "data_pivot['ratio'] = data_pivot[1]/data_pivot[0]*100\n",
    "print(data_pivot.sort_values(by='ratio', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Very interesting and seems significant results getting from education data of the clients. The educated clients the better chance to repay loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Is there a relation between employed status and repaying a loan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pivot = data.pivot_table(\n",
    "index=['employed_satus'],\n",
    "columns='debt',\n",
    "values='total_income', \n",
    "aggfunc='count')\n",
    "\n",
    "data_pivot['ratio'] = data_pivot[1]/data_pivot[0]*100\n",
    "print(data_pivot.sort_values(by='ratio', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also interesting and significant results. People who have dramatically more work experience days - starting from 328727 days - has much more chances to repay loan."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Is there a relation between the customer’s income type and repaying a loan?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_pivot = data.pivot_table(\n",
    "index=['income_type'],\n",
    "columns='debt',\n",
    "values='total_income', \n",
    "aggfunc='count')\n",
    "\n",
    "data_pivot['ratio'] = data_pivot[1]/data_pivot[0]*100\n",
    "print(data_pivot.sort_values(by='ratio', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As seen from the data, people on retirement better repaying loan, as much as civil servants. Business repays loans little worse. The worst loan payers is employes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4. General conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Has been analyzed large amount of data consists information about clients who have some relations with bank debt. The data provided had some errors and inaccuracies which required to deal with them. I made data suitable for analysis by applying a number of functions. \n",
    "\n",
    "Here some preliminary results. Can be primarily designated further hypothesis according to the chances to repay a loan:\n",
    "\n",
    "1. existence of the children decries chances to repay a loan\n",
    "2. (marriage/divorced/widow(er)) status is increase chances to repay a loan;\n",
    "3. rich and middle class repay loans better the poor and lower-middle class;\n",
    "4. loan for auto and education repaying worse, than loans for wedding, commers or real estate costs;\n",
    "5. the educated clients the better chance to repay loan;\n",
    "6. clients with more experience has more chances to repay loan;\n",
    "7. retired, servants and business is better loan payers than employes.\n",
    "\n",
    "Import to remember that results don’t show causation only some correlation between variables. For discovered deeper results, with structural relations and causations among data, more serious statistical analysis required."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
